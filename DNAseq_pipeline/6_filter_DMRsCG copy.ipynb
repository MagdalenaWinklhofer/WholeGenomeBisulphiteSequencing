{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MethylScore output filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "import os\n",
    "import awkward as ak\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Filter for samples are the same in each cluster \n",
    "Since the bed files have different number of column for each row, the dataframe can't be imported with pandas. \n",
    "\n",
    "I open the dataframe and tell it to ignore the first 5 and last 3 column. Those are the one that are uniform throughout the dataframe. I am left with the cluster (numbers) and the cluster list (samples are listed). Hence I calculate the number of elements and only keep half of that (only the listed samples), through which I filter. First, I eliminate the e.g. \"1:\" or \"2:\" and after split all samples in individual elements (split by \",\"). \n",
    "Then I created a for loop, to go through each cluster (sample e.g. \"A2\") and extract the condition e.g. \"A\". If the condition (\"A\") is the same with all the samples that the cluster contains the keep_line=True and it goes on to the next cluster. If all the clusters in one row are True it will append the line (\"row\") to the \"matched_clusters.txt\" file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input_file(input_file_path):\n",
    "    matched_lines = []\n",
    "\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split the line into columns\n",
    "            columns = line.strip().split('\\t')\n",
    "\n",
    "            # Extract the identified clusters column\n",
    "            clusters = columns[5:-3]\n",
    "            num_elements = len(clusters)\n",
    "            last_half = num_elements // 2\n",
    "            clusters = clusters[-last_half:]\n",
    "            clusters = [cluster.split(':')[1] for cluster in clusters]\n",
    "            clusters = [cluster.split(',') for cluster in clusters]\n",
    "            keep_line = True \n",
    "            for cluster in clusters: \n",
    "                condition = cluster[0][0] \n",
    "                for c in cluster:\n",
    "                    if c[0] != condition:\n",
    "                        keep_line = False\n",
    "                        break\n",
    "                if keep_line == False:\n",
    "                    break\n",
    "            if keep_line: \n",
    "                matched_lines.append(line)\n",
    "\n",
    "    # Determine the output file path based on the input file path\n",
    "    output_file_path = os.path.join(os.path.dirname(input_file_path), '1_filtered_clusters.txt')\n",
    "\n",
    "    # Write the matched rows to the output file\n",
    "    with open(output_file_path, 'w') as outfile:\n",
    "        outfile.writelines(matched_lines)\n",
    "\n",
    "# List of input file paths\n",
    "input_files = ['6_DMRsCG/1_NvsA/DMRs.CG.bed', '6_DMRsCG/2_NvsR/DMRs.CG.bed', '6_DMRsCG/3_AvsR/DMRs.CG.bed']\n",
    "\n",
    "# Process each input file\n",
    "for input_file in input_files:\n",
    "    process_input_file(input_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Filter for biologically useful results\n",
    "Since some contain clusters that only contain 2 samples in total this is not biologically relevant. I only want to keep comparisons that are established by a minimum of 6 samples. Hence the following filtering step: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input_file(input_file_path):\n",
    "    # Determine the output file path based on the input file path\n",
    "    output_file_path = os.path.join(os.path.dirname(input_file_path), '2_filtered_min_6samples.txt')\n",
    "\n",
    "    # Reading data from the input file and converting it to an awkward array\n",
    "    array = []\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            columns = line.strip().split('\\t')  # Split the line into columns\n",
    "            array.append(columns)\n",
    "    df = ak.from_iter(array)\n",
    "\n",
    "    # Accessing the 5th column\n",
    "    column_5 = df[:, 4]\n",
    "\n",
    "    # Calculating the number counts for each element\n",
    "    number_counts = [sum(nb.isdigit() for nb in item) for item in column_5]\n",
    "\n",
    "    # Filter for rows with number count of 6 or higher\n",
    "    filtered_indices = [i for i, count in enumerate(number_counts) if count >= 6]\n",
    "\n",
    "    # Writing the filtered rows to the output file\n",
    "    with open(output_file_path, 'w') as outfile:\n",
    "        for idx in filtered_indices:\n",
    "            row = '\\t'.join(str(x) for x in array[idx])\n",
    "            outfile.write(row + '\\n')\n",
    "\n",
    "# List of input file paths\n",
    "input_files = ['6_DMRsCG/1_NvsA/1_filtered_clusters.txt', '6_DMRsCG/2_NvsR/1_filtered_clusters.txt', '6_DMRsCG/3_AvsR/1_filtered_clusters.txt']\n",
    "\n",
    "# Process each input file\n",
    "for input_file in input_files:\n",
    "    process_input_file(input_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Filter for significantly differentially methylated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input_file(input_file_path):\n",
    "    # Determine the output file path based on the input file path\n",
    "    output_file_path = os.path.join(os.path.dirname(input_file_path), '3_sig_diff_meth.txt')\n",
    "\n",
    "    # Reading data from the input file and converting it to an awkward array\n",
    "    array = []\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split the line into columns\n",
    "            columns = line.strip().split('\\t')\n",
    "            array.append(columns)\n",
    "\n",
    "    df = ak.from_iter(array)\n",
    "\n",
    "    # Retrieve the last column as a list\n",
    "    last_col = df[:, -1].tolist()\n",
    "\n",
    "    # Filter the rows for \"CG\" in the last column\n",
    "    filtered_indices = [i for i, col in enumerate(last_col) if \"CG\" in col]\n",
    "\n",
    "    # Get the filtered rows\n",
    "    filtered_rows = df[filtered_indices]\n",
    "\n",
    "    # Write the filtered rows to the output file\n",
    "    with open(output_file_path, 'w') as outfile:\n",
    "        for row in filtered_rows:\n",
    "            row_values = '\\t'.join(str(x) for x in row)\n",
    "            outfile.write(row_values + '\\n')\n",
    "\n",
    "# List of input file paths\n",
    "input_files = ['6_DMRsCG/1_NvsA/2_filtered_min_6samples.txt', '6_DMRsCG/2_NvsR/2_filtered_min_6samples.txt', '6_DMRsCG/3_AvsR/2_filtered_min_6samples.txt']\n",
    "\n",
    "# Process each input file\n",
    "for input_file in input_files:\n",
    "    process_input_file(input_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a copy of the filtered_min6samples files and name them corresponding to the condition comparison that they were created for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of input file paths\n",
    "input_files = ['6_DMRsCG/1_NvsA/2_filtered_min_6samples.txt', '6_DMRsCG/2_NvsR/2_filtered_min_6samples.txt', '6_DMRsCG/3_AvsR/2_filtered_min_6samples.txt']\n",
    "\n",
    "# Process each input file\n",
    "for input_file in input_files:\n",
    "    # Get the folder name from the input file path\n",
    "    folder_name = os.path.dirname(input_file)\n",
    "\n",
    "    # Generate the destination file path with the new name and .txt extension\n",
    "    new_file_name = os.path.basename(folder_name) + \".txt\"\n",
    "    destination_file_path = os.path.join(folder_name, new_file_name)\n",
    "\n",
    "    # Create a copy of the input file with the new name and .txt extension\n",
    "    shutil.copyfile(input_file, destination_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
